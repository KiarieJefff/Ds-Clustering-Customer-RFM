{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0b366d",
   "metadata": {},
   "source": [
    "## **2. Business Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8604da6b",
   "metadata": {},
   "source": [
    "### **2.2 Data Scope**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd2257",
   "metadata": {},
   "source": [
    "- **Origin**: Collected from the UCI Machine Learning Repository ([ID: 352](https://archive.ics.uci.edu/dataset/352/online+retail)). It's a real-world transactional dataset donated for research.\n",
    "- **Format**: Single CSV file (Online_Retail.csv).  \n",
    "- **Scope**: Contains all transactions for a 1-year period (Dec 2010 - Dec 2011) for a UK-based online retailer selling unique gifts, with many wholesale customers.\n",
    "- **Business Relevance**: This dataset directly supports Shoppy's needs by providing:\n",
    "    - Complete transaction history for customer behavior analysis\n",
    "    - Variables essential for segmentation (purchase frequency, monetary value, recency)  \n",
    "    - Customer identifiers for targeted campaign implementation\n",
    "    - Temporal data for understanding engagement patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f2fc5",
   "metadata": {},
   "source": [
    "### **2.3 Data Loading and Initial Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90cfb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (541909, 8)\n",
      "Dataset size: 173.65 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and load data\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path for importing our module\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "# Load raw data\n",
    "df = pd.read_csv('../data/raw/Online_Retail.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Dataset size: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18934b61",
   "metadata": {},
   "source": [
    "### **2.4 Data Assessment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea546e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DATA COLUMN DESCRIPTIONS:\n",
      "==================================================\n",
      "• InvoiceNo: Transaction identifier (6-digit integral number)\n",
      "• StockCode: Product identifier (5-digit integral number)\n",
      "• Description: Product description (text)\n",
      "• Quantity: Items purchased per transaction (numeric)\n",
      "• InvoiceDate: Transaction timestamp (datetime)\n",
      "• UnitPrice: Price per unit in sterling (numeric)\n",
      "• CustomerID: Customer identifier (5-digit integral number)\n",
      "• Country: Customer location (country name)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA COLUMN DESCRIPTIONS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_description = {\n",
    "    'InvoiceNo': 'Transaction identifier (6-digit integral number)',\n",
    "    'StockCode': 'Product identifier (5-digit integral number)',\n",
    "    'Description': 'Product description (text)',\n",
    "    'Quantity': 'Items purchased per transaction (numeric)',\n",
    "    'InvoiceDate': 'Transaction timestamp (datetime)',\n",
    "    'UnitPrice': 'Price per unit in sterling (numeric)',\n",
    "    'CustomerID': 'Customer identifier (5-digit integral number)',\n",
    "    'Country': 'Customer location (country name)'\n",
    "}\n",
    "\n",
    "for col, desc in data_description.items():\n",
    "    print(f\"• {col}: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9b6be",
   "metadata": {},
   "source": [
    "### **2.5 Data Quality Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3dce8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING VALUES ANALYSIS:\n",
      "             Missing_Count  Missing_Percent\n",
      "Description           1454             0.27\n",
      "CustomerID          135080            24.93\n",
      "\n",
      "MISSING DATA IMPACT:\n",
      "• Description missing: 0.27% of transactions\n",
      "• CustomerID missing: 24.93% of transactions\n",
      "• Transactions without CustomerID cannot be used for customer-level analysis\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values using our modular function\n",
    "from data_preprocessing import check_missing_values\n",
    "\n",
    "missing_summary = check_missing_values(df)\n",
    "print(\"MISSING VALUES ANALYSIS:\")\n",
    "print(missing_summary)\n",
    "\n",
    "print(f\"\\nMISSING DATA IMPACT:\")\n",
    "print(f\"• Description missing: {missing_summary.loc['Description', 'Missing_Percent']:.2f}% of transactions\")\n",
    "print(f\"• CustomerID missing: {missing_summary.loc['CustomerID', 'Missing_Percent']:.2f}% of transactions\")\n",
    "print(f\"• Transactions without CustomerID cannot be used for customer-level analysis\")\n",
    "\n",
    "# Note: Function available in src/data_preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9eb5a7",
   "metadata": {},
   "source": [
    "### **2.6 Statistical Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6ac766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATISTICAL SUMMARY:\n",
      "            Quantity      UnitPrice\n",
      "count  541909.000000  541909.000000\n",
      "mean        9.552250       4.611114\n",
      "std       218.081158      96.759853\n",
      "min    -80995.000000  -11062.060000\n",
      "25%         1.000000       1.250000\n",
      "50%         3.000000       2.080000\n",
      "75%        10.000000       4.130000\n",
      "max     80995.000000   38970.000000\n",
      "\n",
      "==================================================\n",
      "KEY INSIGHTS FROM STATISTICS:\n",
      "==================================================\n",
      "• Total Transactions: 541,909\n",
      "• Unique Customers: 4,372\n",
      "• Unique Products: 4,070\n",
      "• Date Range: 01/02/2011 08:23 to 31/10/2011 17:19\n",
      "• Average Quantity per Transaction: 9.55\n",
      "• Average Unit Price: £4.61\n"
     ]
    }
   ],
   "source": [
    "# Display statistical summary for numerical columns\n",
    "print(\"STATISTICAL SUMMARY:\")\n",
    "print(df[['Quantity', 'UnitPrice']].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"KEY INSIGHTS FROM STATISTICS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate additional insights\n",
    "total_transactions = len(df)\n",
    "unique_customers = df['CustomerID'].nunique()\n",
    "unique_products = df['StockCode'].nunique()\n",
    "date_range = f\"{df['InvoiceDate'].min()} to {df['InvoiceDate'].max()}\"\n",
    "\n",
    "print(f\"• Total Transactions: {total_transactions:,}\")\n",
    "print(f\"• Unique Customers: {unique_customers:,}\")\n",
    "print(f\"• Unique Products: {unique_products:,}\")\n",
    "print(f\"• Date Range: {date_range}\")\n",
    "print(f\"• Average Quantity per Transaction: {df['Quantity'].mean():.2f}\")\n",
    "print(f\"• Average Unit Price: £{df['UnitPrice'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febded99",
   "metadata": {},
   "source": [
    "### **2.8 Geographic Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c21bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOGRAPHIC DISTRIBUTION:\n",
      "• Total Countries: 38\n",
      "• Primary Market: United Kingdom (495,478 transactions)\n",
      "• Secondary Markets: Germany (9,495 transactions)\n",
      "\n",
      "TOP 10 COUNTRIES BY TRANSACTION VOLUME:\n",
      "Country\n",
      "United Kingdom    495478\n",
      "Germany             9495\n",
      "France              8557\n",
      "EIRE                8196\n",
      "Spain               2533\n",
      "Netherlands         2371\n",
      "Belgium             2069\n",
      "Switzerland         2002\n",
      "Portugal            1519\n",
      "Australia           1259\n",
      "Name: count, dtype: int64\n",
      "\n",
      "UK Market Dominance: 91.4% of all transactions\n"
     ]
    }
   ],
   "source": [
    "# Analyze country distribution\n",
    "country_counts = df['Country'].value_counts()\n",
    "total_countries = len(country_counts)\n",
    "\n",
    "print(f\"GEOGRAPHIC DISTRIBUTION:\")\n",
    "print(f\"• Total Countries: {total_countries}\")\n",
    "print(f\"• Primary Market: {country_counts.index[0]} ({country_counts.iloc[0]:,} transactions)\")\n",
    "print(f\"• Secondary Markets: {country_counts.index[1]} ({country_counts.iloc[1]:,} transactions)\")\n",
    "\n",
    "print(f\"\\nTOP 10 COUNTRIES BY TRANSACTION VOLUME:\")\n",
    "print(country_counts.head(10))\n",
    "\n",
    "# Calculate UK dominance\n",
    "uk_percentage = (country_counts['United Kingdom'] / len(df)) * 100\n",
    "print(f\"\\nUK Market Dominance: {uk_percentage:.1f}% of all transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca570abb",
   "metadata": {},
   "source": [
    "### **2.9 Business Impact Assessment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b99acbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS IMPACT ASSESSMENT:\n",
      "==================================================\n",
      "DATA QUALITY IMPACT ON SEGMENTATION:\n",
      "• Customer Identification Coverage: 75.1%\n",
      "• Transactions Available for Segmentation: 406,829\n",
      "• Complete Transaction Records: 75.1%\n",
      "\n",
      "BUSINESS VALUE INDICATORS:\n",
      "• Average Revenue per Transaction: £44.05\n",
      "• High-Value Transactions (>£100): 13,554\n",
      "• International Business: 8.6% of transactions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"BUSINESS IMPACT ASSESSMENT:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Assess data quality impact on business objectives\n",
    "print(\"DATA QUALITY IMPACT ON SEGMENTATION:\")\n",
    "\n",
    "# Customer coverage\n",
    "customers_with_id = df['CustomerID'].notna().sum()\n",
    "customer_coverage = (customers_with_id / len(df)) * 100\n",
    "print(f\"• Customer Identification Coverage: {customer_coverage:.1f}%\")\n",
    "print(f\"• Transactions Available for Segmentation: {customers_with_id:,}\")\n",
    "\n",
    "# Transaction completeness\n",
    "complete_transactions = df.dropna(subset=['Description', 'CustomerID']).shape[0]\n",
    "transaction_completeness = (complete_transactions / len(df)) * 100\n",
    "print(f\"• Complete Transaction Records: {transaction_completeness:.1f}%\")\n",
    "\n",
    "# Business value indicators\n",
    "print(f\"\\nBUSINESS VALUE INDICATORS:\")\n",
    "print(f\"• Average Revenue per Transaction: £{df['UnitPrice'].mean() * df['Quantity'].mean():.2f}\")\n",
    "print(f\"• High-Value Transactions (>£100): {(df['UnitPrice'] * df['Quantity'] > 100).sum():,}\")\n",
    "print(f\"• International Business: {(1 - uk_percentage/100):.1%} of transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1aa9de",
   "metadata": {},
   "source": [
    "### **2.10 Data Preparation Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94105a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREPARATION REQUIREMENTS:\n",
      "==================================================\n",
      "REQUIRED TRANSFORMATIONS:\n",
      "1. Missing Value Handling:\n",
      "   • Remove rows with missing Description (affects product analysis)\n",
      "   • Handle missing CustomerID (fill with 'Guest' for transaction-level analysis)\n",
      "\n",
      "2. Data Type Corrections:\n",
      "   • Convert InvoiceDate to datetime format\n",
      "   • Convert CustomerID to string/object type\n",
      "   • Ensure proper numeric types for Quantity and UnitPrice\n",
      "\n",
      "3. Data Cleaning:\n",
      "   • Remove duplicate transactions\n",
      "   • Handle cancelled orders (negative quantities)\n",
      "   • Remove outliers in UnitPrice and Quantity\n",
      "\n",
      "4. Feature Engineering:\n",
      "   • Create Revenue column (Quantity × UnitPrice)\n",
      "   • Extract temporal features (day, month, season)\n",
      "   • Prepare for RFM analysis\n",
      "\n",
      "ESTIMATED DATA RETENTION:\n",
      "• After removing missing CustomerID: 75.1%\n",
      "• After removing duplicates: ~95-98%\n",
      "• After outlier removal: ~85-90%\n",
      "• Final usable data: ~80-85% of original\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"DATA PREPARATION REQUIREMENTS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"REQUIRED TRANSFORMATIONS:\")\n",
    "print(\"1. Missing Value Handling:\")\n",
    "print(\"   • Remove rows with missing Description (affects product analysis)\")\n",
    "print(\"   • Handle missing CustomerID (fill with 'Guest' for transaction-level analysis)\")\n",
    "\n",
    "print(\"\\n2. Data Type Corrections:\")\n",
    "print(\"   • Convert InvoiceDate to datetime format\")\n",
    "print(\"   • Convert CustomerID to string/object type\")\n",
    "print(\"   • Ensure proper numeric types for Quantity and UnitPrice\")\n",
    "\n",
    "print(\"\\n3. Data Cleaning:\")\n",
    "print(\"   • Remove duplicate transactions\")\n",
    "print(\"   • Handle cancelled orders (negative quantities)\")\n",
    "print(\"   • Remove outliers in UnitPrice and Quantity\")\n",
    "\n",
    "print(\"\\n4. Feature Engineering:\")\n",
    "print(\"   • Create Revenue column (Quantity × UnitPrice)\")\n",
    "print(\"   • Extract temporal features (day, month, season)\")\n",
    "print(\"   • Prepare for RFM analysis\")\n",
    "\n",
    "print(f\"\\nESTIMATED DATA RETENTION:\")\n",
    "print(f\"• After removing missing CustomerID: {customer_coverage:.1f}%\")\n",
    "print(f\"• After removing duplicates: ~95-98%\")\n",
    "print(f\"• After outlier removal: ~85-90%\")\n",
    "print(f\"• Final usable data: ~80-85% of original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3b705",
   "metadata": {},
   "source": [
    "### **2.11 Configuration Reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c5c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SOURCE CONFIGURATION:\n",
      "==================================================\n",
      "• Origin: UCI Machine Learning Repository\n",
      "• Dataset Id: 352\n",
      "• Url: https://archive.ics.uci.edu/dataset/352/online+retail\n",
      "• Time Period: Dec 2010 - Dec 2011\n",
      "• Business Type: UK-based online retailer\n",
      "• Description: Complete transaction history for customer behavior analysis\n",
      "\n",
      "ACCESSING CONFIGURATION IN CODE:\n",
      "from src.config import DATA_SOURCE\n",
      "UCI Machine Learning Repository\n",
      "Dec 2010 - Dec 2011\n"
     ]
    }
   ],
   "source": [
    "# Data source information is stored in src/config.py\n",
    "from config import DATA_SOURCE\n",
    "\n",
    "print(\"DATA SOURCE CONFIGURATION:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in DATA_SOURCE.items():\n",
    "    print(f\"• {key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "print(f\"\\nACCESSING CONFIGURATION IN CODE:\")\n",
    "print(\"from src.config import DATA_SOURCE\")\n",
    "print(DATA_SOURCE['origin'])\n",
    "print(DATA_SOURCE['time_period'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a94d1",
   "metadata": {},
   "source": [
    "### **2.12 Summary and Next Steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7842aa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA UNDERSTANDING SUMMARY:\n",
      "==================================================\n",
      "DATASET CHARACTERISTICS:\n",
      "• Dataset contains 541,909 transactions from 38 countries\n",
      "• Time period: Dec 2010 - Dec 2011 (12 months)\n",
      "• 4,372 unique customers with 4,070 unique products\n",
      "• UK-dominated market (91.4% of transactions)\n",
      "\n",
      "DATA QUALITY ASSESSMENT:\n",
      "• Missing CustomerID: 24.9% (major concern)\n",
      "• Missing Description: 0.3% (minor concern)\n",
      "• Data type issues require correction before analysis\n",
      "\n",
      "BUSINESS READINESS:\n",
      "✅ Sufficient transaction volume for segmentation\n",
      "✅ Complete temporal data for RFM analysis\n",
      "✅ Product diversity for behavioral analysis\n",
      "⚠️  Customer ID coverage needs attention\n",
      "⚠️  Data cleaning required before modeling\n",
      "\n",
      "NEXT STEPS:\n",
      "1. Execute data preprocessing pipeline (Data_Preprocessing.ipynb)\n",
      "2. Create customer-level features (Feature_Engineering.ipynb)\n",
      "3. Perform exploratory analysis (EDA.ipynb)\n",
      "4. Develop segmentation model (Modeling.ipynb)\n",
      "\n",
      "Note: Use src/data_preprocessing.py for production data cleaning.\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA UNDERSTANDING SUMMARY:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"DATASET CHARACTERISTICS:\")\n",
    "print(f\"• Dataset contains {len(df):,} transactions from {total_countries} countries\")\n",
    "print(f\"• Time period: Dec 2010 - Dec 2011 (12 months)\")\n",
    "print(f\"• {unique_customers:,} unique customers with {unique_products:,} unique products\")\n",
    "print(f\"• UK-dominated market ({uk_percentage:.1f}% of transactions)\")\n",
    "\n",
    "print(f\"\\nDATA QUALITY ASSESSMENT:\")\n",
    "print(f\"• Missing CustomerID: {missing_summary.loc['CustomerID', 'Missing_Percent']:.1f}% (major concern)\")\n",
    "print(f\"• Missing Description: {missing_summary.loc['Description', 'Missing_Percent']:.1f}% (minor concern)\")\n",
    "print(f\"• Data type issues require correction before analysis\")\n",
    "\n",
    "print(f\"\\nBUSINESS READINESS:\")\n",
    "print(\"✅ Sufficient transaction volume for segmentation\")\n",
    "print(\"✅ Complete temporal data for RFM analysis\")\n",
    "print(\"✅ Product diversity for behavioral analysis\")\n",
    "print(\"⚠️  Customer ID coverage needs attention\")\n",
    "print(\"⚠️  Data cleaning required before modeling\")\n",
    "\n",
    "print(f\"\\nNEXT STEPS:\")\n",
    "print(\"1. Execute data preprocessing pipeline (Data_Preprocessing.ipynb)\")\n",
    "print(\"2. Create customer-level features (Feature_Engineering.ipynb)\")\n",
    "print(\"3. Perform exploratory analysis (EDA.ipynb)\")\n",
    "print(\"4. Develop segmentation model (Modeling.ipynb)\")\n",
    "\n",
    "print(f\"\\nNote: Use src/data_preprocessing.py for production data cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6559f",
   "metadata": {},
   "source": [
    "### **2.7 Data Type Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8772524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT DATA TYPES:\n",
      "InvoiceNo       object\n",
      "StockCode       object\n",
      "Description     object\n",
      "Quantity         int64\n",
      "InvoiceDate     object\n",
      "UnitPrice      float64\n",
      "CustomerID     float64\n",
      "Country         object\n",
      "dtype: object\n",
      "\n",
      "==================================================\n",
      "DATA TYPE ISSUES:\n",
      "==================================================\n",
      "• InvoiceDate stored as object instead of datetime\n",
      "• CustomerID stored as float instead of string/object\n",
      "• 10624 transactions with negative quantities (cancelled orders)\n",
      "• 2 transactions with negative prices\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"CURRENT DATA TYPES:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA TYPE ISSUES:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Identify data type issues\n",
    "data_issues = []\n",
    "\n",
    "if df['InvoiceDate'].dtype == 'object':\n",
    "    data_issues.append(\"• InvoiceDate stored as object instead of datetime\")\n",
    "\n",
    "if df['CustomerID'].dtype == 'float64':\n",
    "    data_issues.append(\"• CustomerID stored as float instead of string/object\")\n",
    "\n",
    "# Check for negative values (cancelled orders)\n",
    "negative_quantity = (df['Quantity'] < 0).sum()\n",
    "negative_price = (df['UnitPrice'] < 0).sum()\n",
    "\n",
    "if negative_quantity > 0:\n",
    "    data_issues.append(f\"• {negative_quantity} transactions with negative quantities (cancelled orders)\")\n",
    "\n",
    "if negative_price > 0:\n",
    "    data_issues.append(f\"• {negative_price} transactions with negative prices\")\n",
    "\n",
    "if data_issues:\n",
    "    for issue in data_issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No major data type issues detected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
